# Alice-s-Adventures-in-a-differentiable-wonderland-chinese
‌[《Alice’s Adventures in a differentiable wonderland》‌是由Simone Scardapane撰写的一本关于深度神经网络的入门书籍。这本书以爱丽丝漫游仙境的故事为背景，通过爱丽丝的冒险经历来介绍深度神经网络的基本概念和设计技巧。本项目是本书的中文翻译版本。


## 前言

本书是关于（深度）神经网络的入门介绍，它是大语言模型、生成式人工智能以及许多其他应用的核心技术。由于“神经”一词带有大量历史包袱，而且神经网络实际上只是可微基元（differentiable primitives）的组合，因此我觉得称之为“可微分模型”是更容易理解的。

2009年，我几乎是偶然地发现了Yoshua Bengio关于“深度”网络的论文[Ben09]，而此时像Theano[ARAA+16]这样的自动微分库正变得流行。就像爱丽丝一样，我闯入了一个奇怪的编程领域——一个可微分的奇妙仙境，在这里，一些简单的操作，比如选择一个元素，非常复杂，而其他事情，比如识别猫，则异常简单。

我花了十多年时间阅读、实现和教授这些思想。本书是我在这个过程中学到的部分知识的粗略总结，重点介绍它们的设计和最常见的组件。由于这一领域发展迅速，我尝试在理论与代码、历史背景与最新趋势之间找到一个良好的平衡。我假设读者对机器学习和线性代数有一定的了解，但在必要时我会补充相关基础知识。

朋友们聚集吧：
是时候开始我们心爱的
爱丽丝在可微分仙境的冒险了。

# 目录

**前言** i  

## 1 引言 

---

# 第一部分 指南  

## 2 数学基础  
### 2.1 线性代数  
### 2.2 梯度与雅可比矩阵  
### 2.3 梯度下降  

## 3 数据集与损失函数   
### 3.1 什么是数据集？  
### 3.2 损失函数  
### 3.3 贝叶斯学习   

## 4 线性模型  
### 4.1 最小二乘回归   
### 4.2 线性分类模型  
### 4.3 进一步探讨分类  

## 5 全连接模型 
### 5.1 线性模型的局限性  
### 5.2 组合与隐藏层 
### 5.3 随机优化 
### 5.4 激活函数 

## 6 自动微分 
### 6.1 问题设定  
### 6.2 正向模式微分  
### 6.3 反向模式微分  
### 6.4 实践考量  

---

# 第二部分 奇异之地 

## 7 卷积层 
### 7.1 走向卷积层 
### 7.2 卷积模型   

## 8 超越图像的卷积 
### 8.1 一维与三维数据的卷积   
### 8.2 一维与三维卷积模型   
### 8.3 预测与因果模型   
### 8.4 生成模型   

## 9 模型的扩展   
### 9.1 ImageNet 挑战   
### 9.2 数据与训练策略   
### 9.3 Dropout 与归一化  
### 9.4 残差连接 

---

# 第三部分 探索深渊  

## 10 Transformer 模型   
### 10.1 长卷积与非局部模型  
### 10.2 位置嵌入  
### 10.3 Transformer 模型的构建   

## 11 Transformer 的实践应用   
### 11.1 编码器-解码器 Transformer   
### 11.2 计算考虑  
### 11.3 Transformer 变体   

## 12 图神经网络  
### 12.1 图数据上的学习   
### 12.2 图卷积层 
### 12.3 超越图卷积层  

## 13 循环神经网络  
### 13.1 线性化注意力模型  
### 13.2 经典循环层 
### 13.3 结构化状态空间模型  
### 13.4 其他变体 

---

# 附录  

## A 概率论  
### A.1 概率基本定律   
### A.2 实值分布  
### A.3 常见分布   
### A.4 矩与期望值   
### A.5 分布间的距离  
### A.6 最大似然估计   

## B 一维通用逼近  
### B.1 逼近阶跃函数   
### B.2 逼近常数函数  
### B.3 逼近任意函数  
